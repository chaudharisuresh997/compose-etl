analysis:
  analyzer:
    ngram_analyzer:
      type: custom
      tokenizer: ngram_tokenizer
      filter:
      - lowercase
    search_analyzer:
      type: custom
      tokenizer: keyword
      filter: lowercase
  tokenizer:
    ngram_tokenizer:
      type: ngram
      min_gram: '2'
      max_gram: '20'
      token_chars:
      - letter
      - digit
